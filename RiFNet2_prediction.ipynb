{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a4eae0e",
   "metadata": {},
   "source": [
    "# RiFNetII"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e053b8a",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cc336a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras import optimizers\n",
    "import math\n",
    "import os, glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from natsort import natsorted\n",
    "#os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "#config = tf.compat.v1.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "#sess = tf.compat.v1.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15b3ece4-c84f-48dd-ae9e-ed86f6e65bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def weighted_f1(y_true, y_pred):\n",
    "    \n",
    "    y_true = np.argmax(y_true.numpy(), axis=1).flatten()\n",
    "    y_pred = np.argmax(y_pred.numpy(), axis=1).flatten()\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a605b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4ffbade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " ['nondisplaced',\n",
       "  'displaced_long_cum_dist',\n",
       "  'displaced_long_cum_cont',\n",
       "  'no_fracture',\n",
       "  'displaced_latus'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = '/Users/victor/Desktop/work/Institute_of_Forensic_Medicine/gui_rifnet/images' \n",
    "image_list = natsorted(os.listdir(image_path))\n",
    "if image_list[0] == '.DS_Store':\n",
    "    image_list = image_list[1:]\n",
    "\n",
    "# define optimizer\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "#os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "learning_rate = 0.00015\n",
    "opt = Adam(lr=0.0001)\n",
    "loss_type = 'categorical_crossentropy' \n",
    "#'RiFNetII_nr_m2_noweight.h5'\n",
    "model_path = '/Users/victor/Desktop/work/Institute_of_Forensic_Medicine/gui_rifnet/ResNet50_full_model.h5'\n",
    "\n",
    "dependencies = {\n",
    "    'weighted_f1': weighted_f1\n",
    "}\n",
    "model = tf.keras.models.load_model(model_path, custom_objects=dependencies, compile=False)\n",
    "model.compile(loss=loss_type,\n",
    "                  optimizer=opt,\n",
    "                  metrics=[Precision(),Recall(),weighted_f1], run_eagerly=True)\n",
    "\n",
    "\n",
    "source_dir = '/Users/victor/Desktop/work/Institute_of_Forensic_Medicine/gui_rifnet/toy_data'\n",
    "classes = os.listdir(source_dir)\n",
    "classes = [x for x in classes if x != '.DS_Store']\n",
    "\n",
    "color_list_fill = [(255,102,255),(102,255,102),(102,255,255),(102,102,255),(107,178,255),(255,102,102),(255,171,102)]\n",
    "color_list_box = [(255,0,255),(0,255,0),(0,255,255),(0,0,255),(0,128,255),(255,0,0),(234,123,10)]\n",
    "\n",
    "# create target folder\n",
    "source_path = '/Users/victor/Desktop/work/Institute_of_Forensic_Medicine/gui_rifnet'\n",
    "pred_path = os.path.join(source_path,'prediction_images_data_all_frac_with_mult')\n",
    "if not os.path.isdir(pred_path):\n",
    "    os.makedirs(pred_path)\n",
    "\n",
    "len(image_list),classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2bc0072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'images'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8d5c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upscale images\n",
    "def upscale(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED) \n",
    "    img = img[250:750, 150:1150]\n",
    "    scale_percent = 300 # percent of original size\n",
    "    width = int(img.shape[1] * scale_percent / 100)\n",
    "    height = int(img.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA) # resize image\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cfccf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub-divide images into small images\n",
    "def sub_divide(resized):\n",
    "    \n",
    "    mapping_array = np.zeros((int(resized.shape[0]/50),int(resized.shape[1]/50)))\n",
    "    small_img_list = []\n",
    "    coord_list = []\n",
    "    shift = 50\n",
    "    \n",
    "    for m in range(0,resized.shape[0]-shift,shift):\n",
    "        for n in range(0,resized.shape[1]-shift,shift):\n",
    "            small_img = resized[m:m+99,n:n+99]\n",
    "            if np.mean(small_img) < 1:\n",
    "                mapping_array[int(m/50)][int(n/50)] = 0\n",
    "                continue\n",
    "            else:\n",
    "                small_img = small_img/255.\n",
    "                small_img_list.append(small_img)\n",
    "                coord_list.append([m,n])\n",
    "                mapping_array[int(m/50)][int(n/50)] = 1\n",
    "                \n",
    "    return small_img_list, coord_list, m, n, mapping_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "617af82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(small_img_list, model):\n",
    "    \n",
    "    small_img_arr = np.array(small_img_list)\n",
    "    results_prob = model.predict(small_img_arr)\n",
    "    results = np.argmax(results_prob,axis=1)\n",
    "    #results = model.predict_classes(small_img_arr)\n",
    "    #results_prob = model.predict_proba(small_img_arr)\n",
    "    #print('predicted on current images...')\n",
    "    return results, results_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b264dea-d630-452f-ad6a-97c1f37f9820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reduced_array(arr,results):\n",
    "    \n",
    "    cnt = 0\n",
    "    \n",
    "    for i in range(arr.shape[0]):\n",
    "        for j in range(arr.shape[1]):\n",
    "            \n",
    "            if arr[i][j] == 0:\n",
    "                continue\n",
    "                \n",
    "            else:\n",
    "\n",
    "                if results[cnt] == 1:\n",
    "                    arr[i][j] = 0\n",
    "\n",
    "                if results[cnt] == 0 or results[cnt] == 2:\n",
    "                    arr[i][j] = 1\n",
    "\n",
    "                cnt += 1\n",
    "                    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6524e802-e552-44ad-9cda-3b0bb5b8a5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiple_coords(mapped_arr):\n",
    "    \n",
    "    coord = []\n",
    "    arr = np.transpose(mapped_arr)\n",
    "\n",
    "    for i in range(arr.shape[0]):\n",
    "        for j in range(arr.shape[1]):\n",
    "            if arr[i][j] == 1:\n",
    "                coord.append([i,j])\n",
    "                \n",
    "    coord_flipped = [[x[1],x[0]] for x in coord]\n",
    "    \n",
    "    full_list = []\n",
    "    flex_list = []\n",
    "    min_dist = 1 # integer\n",
    "    \n",
    "    for t in range(0,len(coord_flipped)-1):\n",
    "\n",
    "        if coord_flipped[t+1][1] - coord_flipped[t][1] <= min_dist:\n",
    "            flex_list.append(coord_flipped[t])\n",
    "\n",
    "        if coord_flipped[t+1][1] - coord_flipped[t][1] <= min_dist and t == len(coord_flipped)-2:\n",
    "            flex_list.append(coord_flipped[t+1])\n",
    "            full_list.append(flex_list)\n",
    "\n",
    "        elif coord_flipped[t+1][1] - coord_flipped[t][1] > min_dist:\n",
    "            flex_list.append(coord_flipped[t])\n",
    "            full_list.append(flex_list)\n",
    "            flex_list = []\n",
    "    \n",
    "    nb_hits = 7\n",
    "    coord_list = []\n",
    "    for i in range(len(full_list)):\n",
    "        if len(full_list[i]) > nb_hits:\n",
    "            c0 = [x[0] for x in full_list[i]]\n",
    "            c1 = [x[1] for x in full_list[i]]\n",
    "            coord_list.append([np.min(list(set(c0))),np.max(list(set(c0))),\n",
    "                              np.min(list(set(c1))),np.max(list(set(c1)))])\n",
    "    \n",
    "    return coord_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6de2ecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rect(resized, results, results_prob, coord_list, cnt,m,n):\n",
    "    \n",
    "    overlay = resized.copy()\n",
    "    \n",
    "    # create prediction matrix\n",
    "    rows = resized.shape[0]\n",
    "    cols = resized.shape[1]\n",
    "    dim = (int((rows/99)*2),int((cols/99)*2))\n",
    "    pred_matrix = np.zeros((m,n))\n",
    "    \n",
    "    # create legend (boxes) in images\n",
    "    for c in range(len(classes2)):\n",
    "        l = c*60\n",
    "        current_color_fill = color_list_fill[c]\n",
    "        current_color_box = color_list_box[c]\n",
    "        overlay[50+l:99+l,50:99] = current_color_fill\n",
    "        cv2.rectangle(resized, (50,50+l), (99,99+l), current_color_box, thickness = 2)\n",
    "        \n",
    "    # create prediction frames on images for each class\n",
    "    row = 0\n",
    "    for r in range(len(results)):\n",
    "        \n",
    "        if r != 0 and r % rows == 0:\n",
    "            row += 1\n",
    "            \n",
    "        current_coordinates = coord_list[r]\n",
    "        m = current_coordinates[0]\n",
    "        n = current_coordinates[1]\n",
    "        \n",
    "        if results[r] == 1:\n",
    "            continue\n",
    "        \n",
    "        elif results[r] != 1:  #and results_prob[r][results[r]] > 0.7:\n",
    "            #pred_matrix[row][r] = 1\n",
    "\n",
    "            if results[r] == 2 or results[r] == 3:\n",
    "                current_color_fill = color_list_fill[results[r]-1]\n",
    "                current_color_box = color_list_box[results[r]-1]\n",
    "            else:\n",
    "                current_color_fill = color_list_fill[results[r]]\n",
    "                current_color_box = color_list_box[results[r]]\n",
    "\n",
    "            #current_coordinates = coord_list[r]\n",
    "             #m = current_coordinates[0]\n",
    "             #n = current_coordinates[1]\n",
    "            overlay[m:m+99,n:n+99] = current_color_fill\n",
    "            cv2.rectangle(resized, (n,m), (n+99,m+99), current_color_box, thickness = 2)\n",
    "            #add = cv2.addWeighted(overlay,0.4,resized,1,0)\n",
    "    \n",
    "    # merge all together and save image\n",
    "    add = cv2.addWeighted(overlay,0.4,resized,0.6,0)\n",
    "    resized = add\n",
    "    \n",
    "    # create legend (writing) in images\n",
    "    for c in range(len(classes2)):\n",
    "        l = c*60\n",
    "        cv2.putText(resized, classes2[c], (120, 85+l), cv2.FONT_HERSHEY_SIMPLEX , 1,(255, 255, 255), 3, cv2.LINE_AA, False)\n",
    "    \n",
    "    # add multiple rectangle\n",
    "    for i in coord_multiple_list:\n",
    "        cv2.rectangle(resized, (i[2]*50,i[0]*50), ((i[3]*50)+100,(i[1]*50)+100), (30,30,240), thickness = 3)\n",
    "        \n",
    "    cv2.imwrite(os.path.join(pred_path, 'test_fracture_%d.jpg' % cnt), resized)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bb734bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed images:  50\n",
      "processed images:  100\n",
      "processed images:  150\n",
      "processed images:  200\n",
      "processed images:  250\n"
     ]
    }
   ],
   "source": [
    "cnt = 1\n",
    "for img in image_list:\n",
    "    if cnt % 50 == 0:\n",
    "        print('processed images: ', cnt)\n",
    "    if '.jpg' not in img:\n",
    "        continue\n",
    "    \n",
    "    else:\n",
    "        current_path = os.path.join(image_path,img)\n",
    "        resized = upscale(current_path)\n",
    "        small_img_list,coord_list,m,n,mapping_array = sub_divide(resized)\n",
    "        results,results_prob = predict(small_img_list, model)\n",
    "        mapped_array = create_reduced_array(mapping_array, results)\n",
    "        coord_multiple_list = get_multiple_coords(mapped_array)\n",
    "        draw_rect(resized,results,results_prob,coord_list,cnt,m,n)\n",
    "        cnt += 1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228646b7-0470-45d0-9cd5-39215aabd4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
