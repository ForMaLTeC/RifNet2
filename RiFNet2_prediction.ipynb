{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a4eae0e",
   "metadata": {},
   "source": [
    "# RiFNetII"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e053b8a",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cc336a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-21 10:38:31.610379: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras import optimizers\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from natsort import natsorted\n",
    "#os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "#config = tf.compat.v1.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "#sess = tf.compat.v1.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15b3ece4-c84f-48dd-ae9e-ed86f6e65bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def weighted_f1(y_true, y_pred):\n",
    "    \n",
    "    y_true = np.argmax(y_true.numpy(), axis=1).flatten()\n",
    "    y_pred = np.argmax(y_pred.numpy(), axis=1).flatten()\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4ffbade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " ['nondisplaced',\n",
       "  'displaced_long_cum_dist',\n",
       "  'displaced_long_cum_cont',\n",
       "  'no_fracture',\n",
       "  'displaced_latus'],\n",
       " ['nondisplaced',\n",
       "  'displaced_long_cum_dist',\n",
       "  'displaced_long_cum_cont',\n",
       "  'displaced_latus'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = '/Users/victor/Desktop/work/Institute_of_Forensic_Medicine/gui_rifnet/images' \n",
    "image_list = natsorted(os.listdir(image_path))\n",
    "if image_list[0] == '.DS_Store':\n",
    "    image_list = image_list[1:]\n",
    "\n",
    "\n",
    "# define optimizer\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "#os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "learning_rate = 0.00015\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "loss_type = 'categorical_crossentropy' \n",
    "\n",
    "model_path = '/Users/victor/Desktop/work/Institute_of_Forensic_Medicine/gui_rifnet/ResNet50_full_model.h5'\n",
    "\n",
    "dependencies = {\n",
    "    'weighted_f1': weighted_f1\n",
    "}\n",
    "model = tf.keras.models.load_model(model_path, custom_objects=dependencies, compile=False)\n",
    "model.compile(loss=loss_type,\n",
    "                  optimizer=opt,\n",
    "                  metrics=[Precision(),Recall(),weighted_f1], run_eagerly=True)\n",
    "\n",
    "\n",
    "\n",
    "source_dir = '/Users/victor/Desktop/work/Institute_of_Forensic_Medicine/gui_rifnet/toy_data'\n",
    "classes = os.listdir(source_dir)\n",
    "classes = [x for x in classes if x != '.DS_Store']\n",
    "classes2 = classes.copy()\n",
    "classes2.remove('no_fracture')\n",
    "\n",
    "color_list_fill = [(255,102,255),(102,255,102),(102,255,255),(102,102,255),(107,178,255),(255,102,102),(255,171,102)]\n",
    "color_list_box = [(255,0,255),(0,255,0),(0,255,255),(0,0,255),(0,128,255),(255,0,0),(234,123,10)]\n",
    "\n",
    "# create target folder\n",
    "source_path = '/Users/victor/Desktop/work/Institute_of_Forensic_Medicine/gui_rifnet'\n",
    "pred_path = os.path.join(source_path,'prediction_images_data_all_frac_with_mult')\n",
    "if not os.path.isdir(pred_path):\n",
    "    os.makedirs(pred_path)\n",
    "\n",
    "len(image_list),classes,classes2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2bc0072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'images'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8d5c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upscale images\n",
    "def upscale(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED) \n",
    "    img = img[250:750, 150:1150]\n",
    "    scale_percent = 300 # percent of original size\n",
    "    width = int(img.shape[1] * scale_percent / 100)\n",
    "    height = int(img.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA) # resize image\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cfccf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub-divide images into small images\n",
    "def sub_divide(resized):\n",
    "    \n",
    "    mapping_array = np.zeros((int(resized.shape[0]/50),int(resized.shape[1]/50)))\n",
    "    small_img_list = []\n",
    "    coord_list = []\n",
    "    shift = 50\n",
    "    \n",
    "    for m in range(0,resized.shape[0]-shift,shift):\n",
    "        for n in range(0,resized.shape[1]-shift,shift):\n",
    "            small_img = resized[m:m+99,n:n+99]\n",
    "            if np.mean(small_img) < 1:\n",
    "                mapping_array[int(m/50)][int(n/50)] = 0\n",
    "                continue\n",
    "            else:\n",
    "                small_img = small_img/255.\n",
    "                small_img_list.append(small_img)\n",
    "                coord_list.append([m,n])\n",
    "                mapping_array[int(m/50)][int(n/50)] = 1\n",
    "                \n",
    "    return small_img_list, coord_list, m, n, mapping_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "617af82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(small_img_list, model):\n",
    "    \n",
    "    small_img_arr = np.array(small_img_list)\n",
    "    results_prob = model.predict(small_img_arr)\n",
    "    results = np.argmax(results_prob,axis=1)\n",
    "    #results = model.predict_classes(small_img_arr)\n",
    "    #results_prob = model.predict_proba(small_img_arr)\n",
    "    #print('predicted on current images...')\n",
    "    return results, results_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b264dea-d630-452f-ad6a-97c1f37f9820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reduced_array(arr,results):\n",
    "    \n",
    "    cnt = 0\n",
    "    \n",
    "    for i in range(arr.shape[0]):\n",
    "        for j in range(arr.shape[1]):\n",
    "            \n",
    "            if arr[i][j] == 0:\n",
    "                continue\n",
    "                \n",
    "            else:\n",
    "\n",
    "                if results[cnt] == 3:\n",
    "                    arr[i][j] = 0\n",
    "\n",
    "                if results[cnt] != 3:\n",
    "                    arr[i][j] = 1\n",
    "\n",
    "                cnt += 1\n",
    "                    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6524e802-e552-44ad-9cda-3b0bb5b8a5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiple_coords(mapped_arr):\n",
    "    \n",
    "    coord = []\n",
    "    arr = np.transpose(mapped_arr)\n",
    "\n",
    "    for i in range(arr.shape[0]):\n",
    "        for j in range(arr.shape[1]):\n",
    "            if arr[i][j] == 1:\n",
    "                coord.append([i,j])\n",
    "                \n",
    "    coord_flipped = [[x[1],x[0]] for x in coord]\n",
    "    \n",
    "    full_list = []\n",
    "    flex_list = []\n",
    "    min_dist = 1 # integer\n",
    "    \n",
    "    for t in range(0,len(coord_flipped)-1):\n",
    "\n",
    "        if coord_flipped[t+1][1] - coord_flipped[t][1] <= min_dist:\n",
    "            flex_list.append(coord_flipped[t])\n",
    "\n",
    "        if coord_flipped[t+1][1] - coord_flipped[t][1] <= min_dist and t == len(coord_flipped)-2:\n",
    "            flex_list.append(coord_flipped[t+1])\n",
    "            full_list.append(flex_list)\n",
    "\n",
    "        elif coord_flipped[t+1][1] - coord_flipped[t][1] > min_dist:\n",
    "            flex_list.append(coord_flipped[t])\n",
    "            full_list.append(flex_list)\n",
    "            flex_list = []\n",
    "    \n",
    "    nb_hits = 7\n",
    "    coord_list = []\n",
    "    for i in range(len(full_list)):\n",
    "        if len(full_list[i]) > nb_hits:\n",
    "            c0 = [x[0] for x in full_list[i]]\n",
    "            c1 = [x[1] for x in full_list[i]]\n",
    "            coord_list.append([np.min(list(set(c0))),np.max(list(set(c0))),\n",
    "                              np.min(list(set(c1))),np.max(list(set(c1)))])\n",
    "    \n",
    "    return coord_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6de2ecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rect(resized, results, results_prob, coord_list, cnt,m,n):\n",
    "    \n",
    "    overlay = resized.copy()\n",
    "    \n",
    "    # create prediction matrix\n",
    "    rows = resized.shape[0]\n",
    "    cols = resized.shape[1]\n",
    "    dim = (int((rows/99)*2),int((cols/99)*2))\n",
    "    pred_matrix = np.zeros((m,n))\n",
    "    \n",
    "    # create legend (boxes) in images\n",
    "    for c in range(len(classes2)):\n",
    "        l = c*60\n",
    "        current_color_fill = color_list_fill[c]\n",
    "        current_color_box = color_list_box[c]\n",
    "        overlay[50+l:99+l,50:99] = current_color_fill\n",
    "        cv2.rectangle(resized, (50,50+l), (99,99+l), current_color_box, thickness = 2)\n",
    "        \n",
    "    # create prediction frames on images for each class\n",
    "    row = 0\n",
    "    for r in range(len(results)):\n",
    "        \n",
    "        if r != 0 and r % rows == 0:\n",
    "            row += 1\n",
    "            \n",
    "        current_coordinates = coord_list[r]\n",
    "        m = current_coordinates[0]\n",
    "        n = current_coordinates[1]\n",
    "        \n",
    "        if results[r] == 3:\n",
    "            continue\n",
    "        \n",
    "        elif results[r] != 3:  #and results_prob[r][results[r]] > 0.7:\n",
    "            #pred_matrix[row][r] = 1\n",
    "            current_color_fill = color_list_fill[results[r]-1]\n",
    "            current_color_box = color_list_box[results[r]-1]\n",
    "            '''\n",
    "            if results[r] == 2 or results[r] == 3:\n",
    "                current_color_fill = color_list_fill[results[r]-1]\n",
    "                current_color_box = color_list_box[results[r]-1]\n",
    "            else:\n",
    "                current_color_fill = color_list_fill[results[r]]\n",
    "                current_color_box = color_list_box[results[r]]\n",
    "            '''\n",
    "            #current_coordinates = coord_list[r]\n",
    "             #m = current_coordinates[0]\n",
    "             #n = current_coordinates[1]\n",
    "            overlay[m:m+99,n:n+99] = current_color_fill\n",
    "            cv2.rectangle(resized, (n,m), (n+99,m+99), current_color_box, thickness = 2)\n",
    "            #add = cv2.addWeighted(overlay,0.4,resized,1,0)\n",
    "    \n",
    "    # merge all together and save image\n",
    "    add = cv2.addWeighted(overlay,0.4,resized,0.6,0)\n",
    "    resized = add\n",
    "    \n",
    "    # create legend (writing) in images\n",
    "    for c in range(len(classes2)):\n",
    "        l = c*60\n",
    "        cv2.putText(resized, classes2[c], (120, 85+l), cv2.FONT_HERSHEY_SIMPLEX , 1,(255, 255, 255), 3, cv2.LINE_AA, False)\n",
    "    \n",
    "    # add multiple rectangle\n",
    "    #for i in coord_multiple_list:\n",
    "        #cv2.rectangle(resized, (i[2]*50,i[0]*50), ((i[3]*50)+100,(i[1]*50)+100), (30,30,240), thickness = 3)\n",
    "        \n",
    "    cv2.imwrite(os.path.join(pred_path, 'test_fracture_%d.jpg' % cnt), resized)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bb734bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 1\n",
    "for img in image_list:\n",
    "    if cnt % 50 == 0:\n",
    "        print('processed images: ', cnt)\n",
    "    if '.jpg' not in img:\n",
    "        continue\n",
    "    \n",
    "    else:\n",
    "        current_path = os.path.join(image_path,img)\n",
    "        resized = upscale(current_path)\n",
    "        small_img_list,coord_list,m,n,mapping_array = sub_divide(resized)\n",
    "        results,results_prob = predict(small_img_list, model)\n",
    "        mapped_array = create_reduced_array(mapping_array, results)\n",
    "        coord_multiple_list = get_multiple_coords(mapped_array)\n",
    "        draw_rect(resized,results,results_prob,coord_list,cnt,m,n)\n",
    "        cnt += 1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "228646b7-0470-45d0-9cd5-39215aabd4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 80s 3s/step\n"
     ]
    }
   ],
   "source": [
    "cnt = 1\n",
    "for img in image_list:\n",
    "    if cnt % 50 == 0:\n",
    "        print('processed images: ', cnt)\n",
    "    if '.jpg' not in img:\n",
    "        continue\n",
    "    \n",
    "    else:\n",
    "        current_path = os.path.join(image_path,img)\n",
    "        resized = upscale(current_path)\n",
    "        small_img_list,coord_list,m,n,mapping_array = sub_divide(resized)\n",
    "        results,results_prob = predict(small_img_list, model)\n",
    "        #mapped_array = create_reduced_array(mapping_array, results)\n",
    "        #coord_multiple_list = get_multiple_coords(mapped_array)\n",
    "        #draw_rect(resized,results,results_prob,coord_list,cnt,m,n)\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06b81430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transparency_func(value):\n",
    "    if value > 0 and value <= 0.2:\n",
    "        return 0.05\n",
    "    if value > 0.2 and value <= 0.4:\n",
    "        return 0.15\n",
    "    if value > 0.4 and value <= 0.6:\n",
    "        return 0.25\n",
    "    if value > 0.6 and value <= 0.8:\n",
    "        return 0.35\n",
    "    if value > 0.8 and value <= 1:\n",
    "        return 0.5    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bee2037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(resized, results, results_prob, coord_list):\n",
    "    \n",
    "    all_masks = []\n",
    "\n",
    "    for nb in range(5):\n",
    "\n",
    "        legend_nbs = [0.15,0.25,0.35,0.45,0.6]\n",
    "        img_to_process = resized.copy()\n",
    "        overlay = resized.copy()\n",
    "        current_color_fill = color_list_fill[nb]\n",
    "        rows = resized.shape[1]\n",
    "        row = 0\n",
    "        for r in range(len(results)):\n",
    "                \n",
    "            if r != 0 and r % rows == 0:\n",
    "                row += 1\n",
    "                \n",
    "            m,n = coord_list[r][0],coord_list[r][1]\n",
    "            \n",
    "            if results[r] == nb:  \n",
    "                \n",
    "                sub_img = overlay[m:m+99,n:n+99]\n",
    "                current_rect = np.ones(sub_img.shape, dtype=np.uint8)\n",
    "                current_rect[0:99,0:99] = current_color_fill\n",
    "                current_prob = results_prob[r][nb]\n",
    "                current_alpha = transparency_func(current_prob)\n",
    "                add = cv2.addWeighted(sub_img,0.5,current_rect,current_alpha,0)\n",
    "                img_to_process[m:m+99,n:n+99] = add\n",
    "\n",
    "        # Add legend with probabilities\n",
    "        y_start = 50\n",
    "        quad_size = 50 \n",
    "        x_start = 1500\n",
    "        y_start = 40\n",
    "        x_shift = 60\n",
    "        y_shift = 0\n",
    "        cv2.putText(img_to_process, 'probability: 0', (x_start-460, 85), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 4, cv2.LINE_AA, False)\n",
    "        cv2.putText(img_to_process, '1', (x_start+350, 85), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 4, cv2.LINE_AA, False)\n",
    "\n",
    "        for n_iter,legend_nb in enumerate(legend_nbs):\n",
    "            sub_img = overlay[y_start+(n_iter*y_shift):y_start+quad_size+(n_iter*y_shift), x_start+(n_iter*x_shift):x_start+quad_size+(n_iter*x_shift)]\n",
    "            current_rect = np.ones(sub_img.shape, dtype=np.uint8)\n",
    "            current_rect[0:quad_size,0:quad_size] = current_color_fill\n",
    "            #current_alpha = transparency_func(legend_nb)\n",
    "            add = cv2.addWeighted(sub_img,0.5,current_rect,legend_nb,0)\n",
    "            img_to_process[y_start+(n_iter*y_shift):y_start+quad_size+(n_iter*y_shift), x_start+(n_iter*x_shift):x_start+quad_size+(n_iter*x_shift)] = add\n",
    "            #cv2.putText(img_to_process, f'>= {n_iter/5}', ((x_start+(n_iter*x_shift))+70, (y_start+(n_iter*y_shift))+40), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 3, cv2.LINE_AA, False)\n",
    "\n",
    "        all_masks.append(img_to_process)\n",
    "    \n",
    "    return all_masks\n",
    "    #plt.imshow(img_to_process)\n",
    "    #plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3eeac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_test(img):\n",
    "    img = img[250:750, 150:1150]\n",
    "    scale_percent = 300 # percent of original size\n",
    "    width = int(img.shape[1] * scale_percent / 100)\n",
    "    height = int(img.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA) # resize image\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "86c0dc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nondisplaced',\n",
       " 'displaced_long_cum_dist',\n",
       " 'displaced_long_cum_cont',\n",
       " 'no_fracture',\n",
       " 'displaced_latus']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02569a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7887\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7887/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 74s 2s/step\n"
     ]
    }
   ],
   "source": [
    "def classify_image(inp):\n",
    "\n",
    "    global all_masks\n",
    "\n",
    "    resized = upscale_test(inp)\n",
    "    small_img_list,coord_list,m,n,mapping_array = sub_divide(resized)\n",
    "    results,results_prob = predict(small_img_list, model)\n",
    "    all_masks = create_mask(resized, results, results_prob, coord_list)\n",
    "    \n",
    "    return 'prediction finished.'\n",
    "\n",
    "def change_img_output(choice):\n",
    "    if choice == \"nondisplaced\":\n",
    "        return all_masks[0]\n",
    "    elif choice == \"displaced latus\":\n",
    "        return all_masks[4]\n",
    "    elif choice == \"displaced longitudinem cum contractione\":\n",
    "        return all_masks[2]\n",
    "    elif choice == \"displaced longitudinem cum distractione\":\n",
    "        return all_masks[1]\n",
    "    else:\n",
    "        return all_masks[3]\n",
    "\n",
    "demo = gr.Blocks()\n",
    "\n",
    "with demo:\n",
    "\n",
    "    gr.Markdown(\n",
    "    \"\"\"\n",
    "    # Rib fracture detection\n",
    "    Choose an image and press \"run prediction\" button below:\n",
    "    \"\"\")\n",
    "\n",
    "    img_file = gr.Image(label=\"Initial image\")\n",
    "    \n",
    "    b1 = gr.Button(\"run prediction\")\n",
    "    text = gr.Textbox(label=\"prediction outcome:\")\n",
    "    \n",
    "    b1.click(classify_image, inputs=img_file, outputs=text)\n",
    "\n",
    "    radio = gr.Radio(\n",
    "        [\"no fracture\", \"nondisplaced\", \"displaced latus\", \n",
    "         \"displaced longitudinem cum distractione\", \"displaced longitudinem cum contractione\"], label=\"Classes to display:\"\n",
    "    )\n",
    "    final_mask = gr.Image(label=\"output image\")\n",
    "    radio.change(fn=change_img_output, inputs=radio, outputs=final_mask)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b64d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16b108ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nondisplaced',\n",
       " 'displaced_long_cum_dist',\n",
       " 'displaced_long_cum_cont',\n",
       " 'no_fracture',\n",
       " 'displaced_latus']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37437576",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
